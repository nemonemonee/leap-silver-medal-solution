{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars\n",
    "import pandas\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "import logging\n",
    "import lightning.pytorch as pl\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from tqdm import tqdm\n",
    "from datasets import LEAPDataset, LEAPTestDataset\n",
    "from ptlit import PTLit\n",
    "from utils import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_seq = torch.load(\"../data/src_seq_p.pt\").to(torch.float32)\n",
    "src_scl = torch.load(\"../data/src_scl_p.pt\").to(torch.float32)\n",
    "labeln = torch.load(\"../data/labeln.pt\").to(torch.float32)\n",
    "labelc = torch.load(\"../data/labelc.pt\").to(torch.float32)\n",
    "labelcc = torch.load(\"../data/labelc1e-5.pt\").to(torch.float32)\n",
    "labelmu = torch.load(\"../data/labelc1e-5mu.pt\").to(torch.float32)\n",
    "labelstd = torch.load(\"../data/labelc1e-5std.pt\").to(torch.float32)\n",
    "mask = torch.load(\"../data/weight.pt\").to(torch.float32).bool()\n",
    "train_ds = LEAPTestDataset(src_seq, src_scl)\n",
    "train_loader = DataLoader(train_ds, batch_size=4096, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(PTLit.load_from_checkpoint(\"../ckpt/kf/lin-c5-0-epoch=53-val_score=0.738.ckpt\").float())\n",
    "models.append(PTLit.load_from_checkpoint(\"../ckpt/te/large-c5-2-epoch=54-val_score=0.747.ckpt\").float())\n",
    "models.append(PTLit.load_from_checkpoint(\"../ckpt/jnet/large-c5-2-epoch=52-val_score=0.746.ckpt\").float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath='ckpt/',\n",
    "    filename='te-base-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=-1,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "logger = TensorBoardLogger(save_dir=\"logger\")\n",
    "trainer = pl.Trainer(\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=1,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[6]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "pred = []\n",
    "for model in models:\n",
    "    pred.append(trainer.predict(model, train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "inverse_mask = ~mask.bool()\n",
    "for p in pred:\n",
    "    ps = torch.cat(p)\n",
    "    ps[:, inverse_mask] = 0.\n",
    "    preds.append(ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 368/368 [18:23<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6916)\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "num_models = len(preds)\n",
    "num_targets = labelc.size(1)\n",
    "ps_f = torch.zeros_like(preds[0])\n",
    "alphas = torch.zeros(num_targets, num_models)\n",
    "def objective(trial, i):\n",
    "    weights = []\n",
    "    remaining_sum = 10\n",
    "    for j in range(num_models - 1):\n",
    "        w_i = trial.suggest_float(f'weight_{j}', 0, remaining_sum, step=.5)\n",
    "        w = w_i / 10.\n",
    "        weights.append(w)\n",
    "        remaining_sum -= w_i\n",
    "\n",
    "    col = sum(weight * preds[m][:, i] for m, weight in enumerate(weights))\n",
    "    return r2_score(col, labeln[:, i])\n",
    "\n",
    "for i in tqdm(range(num_targets)):\n",
    "    if mask[i]:\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(lambda trial: objective(trial, i), n_trials=200)\n",
    "        best_weights = []\n",
    "        remaining_sum = 10.0\n",
    "        for j in range(num_models - 1):\n",
    "            w = study.best_params[f'weight_{j}']\n",
    "            best_weights.append(w / 10.)\n",
    "            remaining_sum -= w\n",
    "        best_weights.append(remaining_sum / 10.) \n",
    "        alphas[i] = torch.tensor(best_weights)\n",
    "        # print(alphas[i])\n",
    "        ps_f[:, i] = sum(weight * preds[m][:, i] for m, weight in enumerate(best_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_seq = torch.load(\"../data/test_seq_p.pt\").to(torch.float32)\n",
    "test_scl = torch.load(\"../data/test_scl_p.pt\").to(torch.float32)\n",
    "test_ds = LEAPTestDataset(test_seq, test_scl)\n",
    "test_loader = DataLoader(test_ds, batch_size=1024, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "for model in models:\n",
    "    test_pred.append(trainer.predict(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = len(test_pred)\n",
    "test_ps_list = [torch.cat(test_pred[m]) for m in range(num_models)]\n",
    "test_ps_final = torch.zeros_like(test_ps_list[0])\n",
    "for i in range(test_ps_final.size(1)):\n",
    "    weighted_sum = torch.zeros_like(test_ps_list[0][:, i])\n",
    "    for m in range(num_models):\n",
    "        a = alphas[i, m].to(torch.float64)\n",
    "        weighted_sum += test_ps_list[m][:, i] * a\n",
    "    test_ps_final[:, i] = weighted_sum\n",
    "test_ps_final = test_ps_final * labelstd + labelmu\n",
    "test_ps_final[:, inverse_mask] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = polars.read_csv('~/leap/data/train.csv')\n",
    "test_df = polars.read_csv('~/leap/data/test.csv')\n",
    "ss = polars.read_csv('~/leap/data/sample_submission.csv', n_rows=1)\n",
    "ss2 = polars.read_csv(\"~/leap/data/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_COLS = df.columns[1:557]\n",
    "TGT_COLS = df.columns[557:]\n",
    "\n",
    "for col in SRC_COLS:\n",
    "    df = df.with_columns(polars.col(col).cast(polars.Float64))\n",
    "    test_df = test_df.with_columns(polars.col(col).cast(polars.Float64))\n",
    "\n",
    "for col in TGT_COLS:\n",
    "    df = df.with_columns(polars.col(col).cast(polars.Float64))\n",
    "    ss = ss.with_columns(polars.col(col).cast(polars.Float64))\n",
    "    ss2 = ss2.with_columns(polars.col(col).cast(polars.Float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = pandas.read_csv(\"~/leap/data/sample_submission.csv\")\n",
    "ss.iloc[:,1:] = test_ps_final.numpy()\n",
    "use_cols = []\n",
    "for i in range(27):\n",
    "    use_cols.append(f\"ptend_q0002_{i}\")\n",
    "\n",
    "# test_df = test_df.to_pandas()\n",
    "for col in use_cols:\n",
    "    ss[col] = - test_df[col.replace(\"ptend\", \"state\")] * ss2[col] / 1200.\n",
    "\n",
    "test_polars = polars.from_pandas(ss[[\"sample_id\"]+TGT_COLS])\n",
    "test_polars.write_csv(\"../outputs/emc555.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /m9400/users/lkv6309/.kaggle/kaggle.json'\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.14 / client 1.6.12)\n",
      "100%|██████████████████████████████████████| 4.07G/4.07G [00:46<00:00, 94.7MB/s]\n",
      "Successfully submitted to LEAP - Atmospheric Physics using AI (ClimSim)"
     ]
    }
   ],
   "source": [
    "! kaggle competitions submit -c leap-atmospheric-physics-ai-climsim -f ../outputs/emn6.csv -m \"7361\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
